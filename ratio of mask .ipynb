{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import / define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import sys\n",
    "import glob\n",
    "import cv2\n",
    "import igraph as ig\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianMixture:\n",
    "    def __init__(self, X, n_components):\n",
    "        self.n_components = n_components\n",
    "        self.n_features = X.shape[1]\n",
    "        self.n_samples = np.zeros(self.n_components)\n",
    "\n",
    "        self.coefs = np.zeros(self.n_components)\n",
    "        self.means = np.zeros((self.n_components, self.n_features))\n",
    "       \n",
    "        self.covariances = np.zeros((self.n_components, self.n_features, self.n_features))\n",
    "        self.init_with_kmeans(X)\n",
    "\n",
    "    def init_with_kmeans(self, X):\n",
    "        label = KMeans(n_clusters=self.n_components, n_init=1).fit(X).labels_\n",
    "        self.fit(X, label)\n",
    "\n",
    "    def calc_score(self, X, ci):\n",
    "        score = np.zeros(X.shape[0])\n",
    "        \n",
    "        if self.coefs[ci] > 0:\n",
    "            diff = X - self.means[ci]\n",
    "            mult = np.einsum('ij,ij->i', diff, np.dot(np.linalg.inv(self.covariances[ci]), diff.T).T)\n",
    "            score = np.exp(-.5 * mult) / np.sqrt(2 * np.pi) / np.sqrt(np.linalg.det(self.covariances[ci]))\n",
    "        \n",
    "        return score\n",
    "\n",
    "    def calc_prob(self, X):\n",
    "        prob = [self.calc_score(X, ci) for ci in range(self.n_components)]\n",
    "        \n",
    "        return np.dot(self.coefs, prob)\n",
    "\n",
    "    def which_component(self, X):\n",
    "        prob = np.array([self.calc_score(X, ci) for ci in range(self.n_components)]).T\n",
    "\n",
    "        return np.argmax(prob, axis=1)\n",
    "\n",
    "    def fit(self, X, labels):\n",
    "        assert self.n_features == X.shape[1]\n",
    "\n",
    "        self.n_samples[:] = 0\n",
    "        self.coefs[:] = 0\n",
    "\n",
    "        uni_labels, count = np.unique(labels, return_counts=True)\n",
    "        self.n_samples[uni_labels] = count\n",
    "\n",
    "        variance = 0.01\n",
    "        for ci in uni_labels:\n",
    "            n = self.n_samples[ci]\n",
    "\n",
    "            self.coefs[ci] = n / np.sum(self.n_samples)\n",
    "            self.means[ci] = np.mean(X[ci == labels], axis=0)\n",
    "            self.covariances[ci] = 0 if self.n_samples[ci] <= 1 else np.cov(X[ci == labels].T)\n",
    "\n",
    "            det = np.linalg.det(self.covariances[ci])\n",
    "            if det <= 0:\n",
    "                self.covariances[ci] += np.eye(self.n_features) * variance\n",
    "                det = np.linalg.det(self.covariances[ci])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrabCut:\n",
    "    def __init__(self, img, mask,num_iters, gamma,gmm_components,flag,rect=None):\n",
    "        self.img = np.asarray(img, dtype=np.float64)\n",
    "        self.rows, self.cols, _ = img.shape\n",
    "        self.mask = mask\n",
    "        \n",
    "        if rect is not None:\n",
    "            self.mask[rect[1]:rect[1] + rect[3],rect[0]:rect[0] + rect[2]] = DRAW_PR_FG['val']\n",
    "        \n",
    "        self.classify_pixels()\n",
    "\n",
    "        # Best number of GMM components K suggested in paper\n",
    "        self.gmm_components = gmm_components\n",
    "        \n",
    "        # Best gamma suggested in paper formula (5)\n",
    "        self.gamma = gamma \n",
    "        \n",
    "        self.beta = 0\n",
    "\n",
    "        self.left_V = np.empty((self.rows, self.cols - 1))\n",
    "        self.upright_V = np.empty((self.rows - 1, self.cols - 1))\n",
    "        \n",
    "        if flag==8:\n",
    "            self.upleft_V = np.empty((self.rows - 1, self.cols - 1))\n",
    "            self.up_V = np.empty((self.rows - 1, self.cols))\n",
    "\n",
    "        self.bgd_gmm = None\n",
    "        self.fgd_gmm = None\n",
    "        self.comp_idxs = np.empty((self.rows, self.cols), dtype=np.uint32)\n",
    "\n",
    "        self.gc_graph = None\n",
    "        self.gc_graph_capacity = None           # Edge capacities\n",
    "        self.gc_source = self.cols * self.rows  # \"object\" terminal S\n",
    "        self.gc_sink = self.gc_source + 1       # \"background\" terminal T\n",
    "\n",
    "        self.calc_beta_smoothness()\n",
    "        self.init_GMMs()\n",
    "        self.run(num_iters)\n",
    "\n",
    "    def calc_beta_smoothness(self):\n",
    "        _left_diff = self.img[:, 1:] - self.img[:, :-1]\n",
    "        _up_diff = self.img[1:, :] - self.img[:-1, :]\n",
    "        \n",
    "        if flag==8:\n",
    "            _upleft_diff = self.img[1:, 1:] - self.img[:-1, :-1]\n",
    "            _upright_diff = self.img[1:, :-1] - self.img[:-1, 1:]   \n",
    "            self.beta = np.sum(np.square(_left_diff)) + np.sum(np.square(_upleft_diff)) + \\\n",
    "                np.sum(np.square(_up_diff)) + np.sum(np.square(_upright_diff))\n",
    "            self.beta = 1 / (2 * self.beta / (\n",
    "                # Each pixel has 4 neighbors (left, upleft, up, upright)\n",
    "                4 * self.cols * self.rows\n",
    "                # The 1st column doesn't have left, upleft and the last column doesn't have upright\n",
    "                - 3 * self.cols\n",
    "                - 3 * self.rows  # The first row doesn't have upleft, up and upright\n",
    "                + 2))  # The first and last pixels in the 1st row are removed twice\n",
    "        else:\n",
    "            self.beta = np.sum(np.square(_left_diff)) + np.sum(np.square(_up_diff)) \n",
    "            self.beta = 1 / (2 * self.beta / (\n",
    "            # Each pixel has 2 neighbors (left,up)\n",
    "            2 * self.cols * self.rows\n",
    "            # The 1st column doesn't have left\n",
    "            - self.cols\n",
    "            # The first row doesn't have up\n",
    "            - self.rows))\n",
    "#         print('Beta:', self.beta)\n",
    "\n",
    "        # Smoothness term V described in formula (11)\n",
    "        self.left_V = self.gamma * np.exp(-self.beta * np.sum(np.square(_left_diff), axis=2))\n",
    "        self.up_V = self.gamma * np.exp(-self.beta * np.sum(np.square(_up_diff), axis=2))\n",
    "        \n",
    "        if flag==8:\n",
    "            self.upleft_V = self.gamma / np.sqrt(2) * np.exp(-self.beta * np.sum(np.square(_upleft_diff), axis=2))\n",
    "            self.upright_V = self.gamma / np.sqrt(2) * np.exp(-self.beta * np.sum(np.square(_upright_diff), axis=2))\n",
    "\n",
    "\n",
    "    def classify_pixels(self):\n",
    "        self.bgd_indexes = np.where(np.logical_or(self.mask == DRAW_BG['val'], self.mask == DRAW_PR_BG['val']))\n",
    "        self.fgd_indexes = np.where(np.logical_or(self.mask == DRAW_FG['val'], self.mask == DRAW_PR_FG['val']))\n",
    "\n",
    "        assert self.bgd_indexes[0].size > 0\n",
    "        assert self.fgd_indexes[0].size > 0\n",
    "\n",
    "#         print('(pr_)bgd count: %d, (pr_)fgd count: %d' % (self.bgd_indexes[0].size, self.fgd_indexes[0].size))\n",
    "\n",
    "    def init_GMMs(self):\n",
    "        self.bgd_gmm = GaussianMixture(self.img[self.bgd_indexes],gmm_components)\n",
    "        self.fgd_gmm = GaussianMixture(self.img[self.fgd_indexes],gmm_components)\n",
    "\n",
    "    def assign_GMMs_components(self):\n",
    "        #Step 1 in Figure 3: Assign GMM components to pixels\n",
    "        self.comp_idxs[self.bgd_indexes] = self.bgd_gmm.which_component(self.img[self.bgd_indexes])\n",
    "        self.comp_idxs[self.fgd_indexes] = self.fgd_gmm.which_component(self.img[self.fgd_indexes])\n",
    "\n",
    "    def learn_GMMs(self):\n",
    "        #Step 2 in Figure 3: Learn GMM parameters from data z\n",
    "        self.bgd_gmm.fit(self.img[self.bgd_indexes],self.comp_idxs[self.bgd_indexes])\n",
    "        self.fgd_gmm.fit(self.img[self.fgd_indexes],self.comp_idxs[self.fgd_indexes])\n",
    "\n",
    "    def construct_gc_graph(self):\n",
    "        bgd_indexes = np.where(self.mask.reshape(-1) == DRAW_BG['val'])\n",
    "        fgd_indexes = np.where(self.mask.reshape(-1) == DRAW_FG['val'])\n",
    "        pr_indexes = np.where(np.logical_or(self.mask.reshape(-1) == DRAW_PR_BG['val'], self.mask.reshape(-1) == DRAW_PR_FG['val']))\n",
    "\n",
    "#         print('bgd count: %d, fgd count: %d, uncertain count: %d' % (len(bgd_indexes[0]), len(fgd_indexes[0]), len(pr_indexes[0])))\n",
    "\n",
    "        edges = []\n",
    "        self.gc_graph_capacity = []\n",
    "\n",
    "        # t-links\n",
    "        edges.extend(\n",
    "            list(zip([self.gc_source] * pr_indexes[0].size, pr_indexes[0])))\n",
    "        _D = -np.log(self.bgd_gmm.calc_prob(self.img.reshape(-1, 3)[pr_indexes]))\n",
    "        self.gc_graph_capacity.extend(_D.tolist())\n",
    "        assert len(edges) == len(self.gc_graph_capacity)\n",
    "\n",
    "        edges.extend(\n",
    "            list(zip([self.gc_sink] * pr_indexes[0].size, pr_indexes[0])))\n",
    "        _D = -np.log(self.fgd_gmm.calc_prob(self.img.reshape(-1, 3)[pr_indexes]))\n",
    "        self.gc_graph_capacity.extend(_D.tolist())\n",
    "        assert len(edges) == len(self.gc_graph_capacity)\n",
    "\n",
    "        edges.extend(\n",
    "            list(zip([self.gc_source] * bgd_indexes[0].size, bgd_indexes[0])))\n",
    "        self.gc_graph_capacity.extend([0] * bgd_indexes[0].size)\n",
    "        assert len(edges) == len(self.gc_graph_capacity)\n",
    "\n",
    "        edges.extend(\n",
    "            list(zip([self.gc_sink] * bgd_indexes[0].size, bgd_indexes[0])))\n",
    "        self.gc_graph_capacity.extend([9 * self.gamma] * bgd_indexes[0].size)\n",
    "        assert len(edges) == len(self.gc_graph_capacity)\n",
    "\n",
    "        edges.extend(\n",
    "            list(zip([self.gc_source] * fgd_indexes[0].size, fgd_indexes[0])))\n",
    "        self.gc_graph_capacity.extend([9 * self.gamma] * fgd_indexes[0].size)\n",
    "        assert len(edges) == len(self.gc_graph_capacity)\n",
    "\n",
    "        edges.extend(\n",
    "            list(zip([self.gc_sink] * fgd_indexes[0].size, fgd_indexes[0])))\n",
    "        self.gc_graph_capacity.extend([0] * fgd_indexes[0].size)\n",
    "        assert len(edges) == len(self.gc_graph_capacity)\n",
    "\n",
    "        # n-links\n",
    "        img_indexes = np.arange(self.rows * self.cols,dtype=np.uint32).reshape(self.rows, self.cols)\n",
    "\n",
    "        mask1 = img_indexes[:, 1:].reshape(-1)\n",
    "        mask2 = img_indexes[:, :-1].reshape(-1)\n",
    "        edges.extend(list(zip(mask1, mask2)))\n",
    "        self.gc_graph_capacity.extend(self.left_V.reshape(-1).tolist())\n",
    "        assert len(edges) == len(self.gc_graph_capacity)\n",
    "\n",
    "        mask1 = img_indexes[1:, :].reshape(-1)\n",
    "        mask2 = img_indexes[:-1, :].reshape(-1)\n",
    "        edges.extend(list(zip(mask1, mask2)))\n",
    "        self.gc_graph_capacity.extend(self.up_V.reshape(-1).tolist())\n",
    "        assert len(edges) == len(self.gc_graph_capacity)\n",
    "        \n",
    "        if flag==8:\n",
    "        \n",
    "            mask1 = img_indexes[1:, 1:].reshape(-1)\n",
    "            mask2 = img_indexes[:-1, :-1].reshape(-1)\n",
    "            edges.extend(list(zip(mask1, mask2)))\n",
    "            self.gc_graph_capacity.extend(self.upleft_V.reshape(-1).tolist())\n",
    "            assert len(edges) == len(self.gc_graph_capacity)\n",
    "\n",
    "            mask1 = img_indexes[1:, :-1].reshape(-1)\n",
    "            mask2 = img_indexes[:-1, 1:].reshape(-1)\n",
    "            edges.extend(list(zip(mask1, mask2)))\n",
    "            self.gc_graph_capacity.extend(self.upright_V.reshape(-1).tolist())\n",
    "            assert len(edges) == len(self.gc_graph_capacity)\n",
    "            \n",
    "            assert len(edges) == 4 * self.cols * self.rows - 3 * (self.cols + self.rows) + 2 +2 * self.cols * self.rows\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            assert len(edges) == 2 * self.cols * self.rows - (self.cols + self.rows) + 2* self.cols * self.rows\n",
    "\n",
    "        \n",
    "        self.gc_graph = ig.Graph(self.cols * self.rows + 2)\n",
    "        self.gc_graph.add_edges(edges)\n",
    "\n",
    "    def estimate_segmentation(self):\n",
    "        #Step 3 in Figure 3: Estimate segmentation\n",
    "        mincut = self.gc_graph.st_mincut(self.gc_source, self.gc_sink, self.gc_graph_capacity)\n",
    "#         print('foreground pixels: %d, background pixels: %d' % (len(mincut.partition[0]), len(mincut.partition[1])))\n",
    "        pr_indexes = np.where(np.logical_or(self.mask == DRAW_PR_BG['val'], self.mask == DRAW_PR_FG['val']))\n",
    "        img_indexes = np.arange(self.rows * self.cols, dtype=np.uint32).reshape(self.rows, self.cols)\n",
    "        self.mask[pr_indexes] = np.where(np.isin(img_indexes[pr_indexes], mincut.partition[0]),DRAW_PR_FG['val'], DRAW_PR_BG['val'])\n",
    "        self.classify_pixels()\n",
    "        \n",
    "    def run(self, num_iters):\n",
    "        for _ in range(num_iters):\n",
    "            self.assign_GMMs_components()\n",
    "            self.learn_GMMs()\n",
    "            self.construct_gc_graph()\n",
    "            self.estimate_segmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining variables and flags\n",
    "# BLUE = [255, 0, 0]\n",
    "DRAW_BG = { 'val': 0}\n",
    "DRAW_FG = { 'val': 1}\n",
    "DRAW_PR_FG = {'val': 3}\n",
    "DRAW_PR_BG = {'val': 2}\n",
    "\n",
    "# setting up flags\n",
    "rect = (0, 0, 1, 1)\n",
    "rectangle = False       # flag for drawing rect\n",
    "rect_over = False       # flag to check if rect drawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 120, 3)\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 27.0625 %\n"
     ]
    }
   ],
   "source": [
    "filename=\"./masked_dataset_face_cropped/16/n_16_fron_face.jpg\"\n",
    "\n",
    "gmm_components=5\n",
    "num_iters=1\n",
    "gamma=50\n",
    "flag=8\n",
    "img = cv2.imread(filename)\n",
    "\n",
    "# auto_grabcut\n",
    "img2 = img.copy() # a copy of original image\n",
    "\n",
    "mask = np.zeros(img.shape[:2], dtype=np.uint8)  # mask initialized to BG\n",
    "auto_grabcut = np.zeros(img.shape, np.uint8)    # output image to be shown\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "rect = (1, 1, img.shape[1]-2, img.shape[0]-2)\n",
    "rectangle = True # test\n",
    "rect_over =  True # test\n",
    "print(rect, rect)\n",
    "gc = GrabCut(img2, mask,num_iters,gamma,gmm_components, flag,rect)\n",
    "\n",
    "mask2 = np.where((mask == 1) + (mask == 3), 255, 0).astype('uint8')\n",
    "auto_grabcut = cv2.bitwise_and(img2, img2, mask=mask2)\n",
    "\n",
    "# hsv_mask\n",
    "hsv = cv2.cvtColor(auto_grabcut, cv2.COLOR_BGR2HSV)\n",
    "h, s, v = cv2.split(hsv)\n",
    "\n",
    "\n",
    "s = cv2.inRange(s, 0, 50) ##### hsv 범위 조절\n",
    "hsv_mask = cv2.bitwise_and(hsv, hsv, mask = s)\n",
    "hsv_mask = cv2.cvtColor(hsv_mask, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "# calculate ratio\n",
    "img_gray = cv2.cvtColor(hsv_mask, cv2.COLOR_BGR2GRAY)\n",
    "img_bin = np.zeros(img_gray.shape)\n",
    "\n",
    "no_mask_px_cnt = 0\n",
    "mask_px_cnt = 0\n",
    "\n",
    "for i in range(0, img_gray.shape[0]):\n",
    "    for j in range(0, img_gray.shape[1]):\n",
    "        if img_gray[i][j] == 0:\n",
    "            img_bin[i][j] = 0 # no_mask_px\n",
    "            no_mask_px_cnt = no_mask_px_cnt + 1\n",
    "        else:\n",
    "            img_bin[i][j] = 255 # mask_px\n",
    "            mask_px_cnt = mask_px_cnt + 1\n",
    "\n",
    "print(\"the ratio of mask:\", mask_px_cnt/(mask_px_cnt+no_mask_px_cnt)*100, \"%\")\n",
    "# 마스크로 가려진 부분의 비율(단위: %)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "cv2.namedWindow(\"1. input\", cv2.WINDOW_NORMAL) # 창 크기 조절 가능\n",
    "cv2.imshow(\"1. input\", img)\n",
    "\n",
    "cv2.namedWindow(\"2. auto_grabcut\", cv2.WINDOW_NORMAL) # 창 크기 조절 가능\n",
    "cv2.imshow(\"2. auto_grabcut\", auto_grabcut)\n",
    "\n",
    "cv2.namedWindow(\"3. hsv\", cv2.WINDOW_NORMAL) # 창 크기 조절 가능\n",
    "cv2.imshow(\"3. hsv\", hsv_mask)\n",
    "\n",
    "cv2.namedWindow(\"4. binary image\", cv2.WINDOW_NORMAL) # 창 크기 조절 가능\n",
    "cv2.imshow(\"4. binary image\",img_bin)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 반복문으로 여러 이미지의 평균 비율 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./masked_dataset_face_cropped/03/f_03_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 37.94245171462357 %\n",
      "\n",
      "./masked_dataset_face_cropped/03/f_03_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 27.184185845177115 %\n",
      "\n",
      "./masked_dataset_face_cropped/03/f_03_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 20.854071990189713 %\n",
      "\n",
      "./masked_dataset_face_cropped/03/n_03_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 23.990642215681834 %\n",
      "\n",
      "./masked_dataset_face_cropped/03/n_03_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 24.31469497564168 %\n",
      "\n",
      "./masked_dataset_face_cropped/03/n_03_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 18.523019731198172 %\n",
      "\n",
      "./masked_dataset_face_cropped/04/f_04_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 39.276563677467976 %\n",
      "\n",
      "./masked_dataset_face_cropped/04/f_04_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 28.93509953378228 %\n",
      "\n",
      "./masked_dataset_face_cropped/04/f_04_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 26.04053956575056 %\n",
      "\n",
      "./masked_dataset_face_cropped/04/n_04_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 28.58945597307908 %\n",
      "\n",
      "./masked_dataset_face_cropped/04/n_04_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 20.70109636468552 %\n",
      "\n",
      "./masked_dataset_face_cropped/04/n_04_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 0.5712179841533075 %\n",
      "\n",
      "./masked_dataset_face_cropped/05/f_05_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 40.476190476190474 %\n",
      "\n",
      "./masked_dataset_face_cropped/05/f_05_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 32.19039351851852 %\n",
      "\n",
      "./masked_dataset_face_cropped/05/f_05_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 37.55565791493935 %\n",
      "\n",
      "./masked_dataset_face_cropped/05/n_05_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 29.571386775892332 %\n",
      "\n",
      "./masked_dataset_face_cropped/05/n_05_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 30.303734697040134 %\n",
      "\n",
      "./masked_dataset_face_cropped/05/n_05_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 27.427329937069224 %\n",
      "\n",
      "./masked_dataset_face_cropped/06/f_06_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 18.132506780317705 %\n",
      "\n",
      "./masked_dataset_face_cropped/06/f_06_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 26.505139500734217 %\n",
      "\n",
      "./masked_dataset_face_cropped/06/f_06_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 20.938545786431394 %\n",
      "\n",
      "./masked_dataset_face_cropped/06/n_06_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 11.262318160488034 %\n",
      "\n",
      "./masked_dataset_face_cropped/06/n_06_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 9.873776981103891 %\n",
      "\n",
      "./masked_dataset_face_cropped/06/n_06_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 8.68193160135036 %\n",
      "\n",
      "./masked_dataset_face_cropped/08/f_08_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 19.363543314413327 %\n",
      "\n",
      "./masked_dataset_face_cropped/08/f_08_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 13.067632850241544 %\n",
      "\n",
      "./masked_dataset_face_cropped/08/f_08_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 9.30199019325065 %\n",
      "\n",
      "./masked_dataset_face_cropped/08/n_08_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 16.242796772954282 %\n",
      "\n",
      "./masked_dataset_face_cropped/08/n_08_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 16.129277566539923 %\n",
      "\n",
      "./masked_dataset_face_cropped/08/n_08_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 12.728977354680513 %\n",
      "\n",
      "./masked_dataset_face_cropped/09/f_09_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 33.40638399237732 %\n",
      "\n",
      "./masked_dataset_face_cropped/09/f_09_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 29.498502419169036 %\n",
      "\n",
      "./masked_dataset_face_cropped/09/f_09_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 26.84630738522954 %\n",
      "\n",
      "./masked_dataset_face_cropped/09/n-09_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 18.991254523522315 %\n",
      "\n",
      "./masked_dataset_face_cropped/09/n_09_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 26.645361893245813 %\n",
      "\n",
      "./masked_dataset_face_cropped/09/n_09_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 23.34175615919141 %\n",
      "\n",
      "./masked_dataset_face_cropped/10/f_10_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 38.3000276268533 %\n",
      "\n",
      "./masked_dataset_face_cropped/10/f_10_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 28.30023131530669 %\n",
      "\n",
      "./masked_dataset_face_cropped/10/f_10_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 25.982351610227017 %\n",
      "\n",
      "./masked_dataset_face_cropped/10/n_10_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 23.2924851324563 %\n",
      "\n",
      "./masked_dataset_face_cropped/10/n_10_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 20.65175620628699 %\n",
      "\n",
      "./masked_dataset_face_cropped/10/n_10_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 16.742909423604758 %\n",
      "\n",
      "./masked_dataset_face_cropped/14/f_14_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 22.317660125879303 %\n",
      "\n",
      "./masked_dataset_face_cropped/14/f_14_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 25.002226774739466 %\n",
      "\n",
      "./masked_dataset_face_cropped/14/f_14_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 24.579292050070464 %\n",
      "\n",
      "./masked_dataset_face_cropped/14/n_14_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 27.626124364489634 %\n",
      "\n",
      "./masked_dataset_face_cropped/14/n_14_fon_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 21.7305872935012 %\n",
      "\n",
      "./masked_dataset_face_cropped/14/n_14_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 17.90895447723862 %\n",
      "\n",
      "./masked_dataset_face_cropped/15/f_15_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 31.740123509009386 %\n",
      "\n",
      "./masked_dataset_face_cropped/15/f_15_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 30.252286810268515 %\n",
      "\n",
      "./masked_dataset_face_cropped/15/f_15_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 24.937007234007964 %\n",
      "\n",
      "./masked_dataset_face_cropped/15/n_15_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 0.13388989525084666 %\n",
      "\n",
      "./masked_dataset_face_cropped/15/n_15_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 24.86789691894968 %\n",
      "\n",
      "./masked_dataset_face_cropped/15/n_15_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 25.52214486742705 %\n",
      "\n",
      "./masked_dataset_face_cropped/17/f_17_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 30.453066730143618 %\n",
      "\n",
      "./masked_dataset_face_cropped/17/f_17_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 32.22869628550619 %\n",
      "\n",
      "./masked_dataset_face_cropped/17/f_17_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIMA_GRAM\\Anaconda3\\envs\\ny_tf\\lib\\site-packages\\ipykernel_launcher.py:112: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the ratio of mask: 29.659769045958306 %\n",
      "\n",
      "./masked_dataset_face_cropped/17/n_17_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 26.05062082139446 %\n",
      "\n",
      "./masked_dataset_face_cropped/17/n_17_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 26.822289156626507 %\n",
      "\n",
      "./masked_dataset_face_cropped/17/n_17_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 24.657635650307203 %\n",
      "\n",
      "./masked_dataset_face_cropped/20/f_20_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 41.738995660260386 %\n",
      "\n",
      "./masked_dataset_face_cropped/20/f_20_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 20.867163304595294 %\n",
      "\n",
      "./masked_dataset_face_cropped/20/f_20_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 18.661137440758292 %\n",
      "\n",
      "./masked_dataset_face_cropped/20/h_20_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 37.644285482035436 %\n",
      "\n",
      "./masked_dataset_face_cropped/20/h_20_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 16.19497999272463 %\n",
      "\n",
      "./masked_dataset_face_cropped/20/h_20_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 12.05658001925498 %\n",
      "\n",
      "./masked_dataset_face_cropped/21/f_21_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 20.880985759610418 %\n",
      "\n",
      "./masked_dataset_face_cropped/21/f_21_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 16.175657531000713 %\n",
      "\n",
      "./masked_dataset_face_cropped/21/f_21_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 18.08077873020485 %\n",
      "\n",
      "./masked_dataset_face_cropped/21/h_21_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 22.661815976959225 %\n",
      "\n",
      "./masked_dataset_face_cropped/21/h_21_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 22.636165577342048 %\n",
      "\n",
      "./masked_dataset_face_cropped/21/h_21_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 20.046480245895495 %\n",
      "\n",
      "./masked_dataset_face_cropped/24/f_24_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 31.749227119131497 %\n",
      "\n",
      "./masked_dataset_face_cropped/24/f_24_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 25.263527758257204 %\n",
      "\n",
      "./masked_dataset_face_cropped/24/f_24_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 22.277700271679272 %\n",
      "\n",
      "./masked_dataset_face_cropped/24/h_24_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 22.75609197158353 %\n",
      "\n",
      "./masked_dataset_face_cropped/24/h_24_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 19.06122740587269 %\n",
      "\n",
      "./masked_dataset_face_cropped/24/h_24_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 14.228514228514227 %\n",
      "\n",
      "./masked_dataset_face_cropped/25/f_25_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 24.72126413732253 %\n",
      "\n",
      "./masked_dataset_face_cropped/25/f_25_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 20.086265223274697 %\n",
      "\n",
      "./masked_dataset_face_cropped/25/f_25_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 12.532505056342098 %\n",
      "\n",
      "./masked_dataset_face_cropped/25/h_25_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 18.584496870486277 %\n",
      "\n",
      "./masked_dataset_face_cropped/25/h_25_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 15.651599647783973 %\n",
      "\n",
      "./masked_dataset_face_cropped/25/h_25_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 5.616511931251439 %\n",
      "\n",
      "./masked_dataset_face_cropped/28/f_28_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 29.2421388204608 %\n",
      "\n",
      "./masked_dataset_face_cropped/28/f_28_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 33.82384152812168 %\n",
      "\n",
      "./masked_dataset_face_cropped/28/f_28_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 21.2372312308022 %\n",
      "\n",
      "./masked_dataset_face_cropped/28/h_28_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 24.848030018761726 %\n",
      "\n",
      "./masked_dataset_face_cropped/28/h_28_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 20.17994858611825 %\n",
      "\n",
      "./masked_dataset_face_cropped/28/h_28_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 14.249778040840486 %\n",
      "\n",
      "./masked_dataset_face_cropped/31/f_31_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 35.032422227694326 %\n",
      "\n",
      "./masked_dataset_face_cropped/31/f_31_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 21.61001258979486 %\n",
      "\n",
      "./masked_dataset_face_cropped/31/f_31_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 23.957883835332698 %\n",
      "\n",
      "./masked_dataset_face_cropped/31/h_31_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 30.927617709065352 %\n",
      "\n",
      "./masked_dataset_face_cropped/31/h_31_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 27.64973283355929 %\n",
      "\n",
      "./masked_dataset_face_cropped/31/h_31_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 21.901845073578848 %\n",
      "\n",
      "./masked_dataset_face_cropped/32/f_32_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 40.68717369832087 %\n",
      "\n",
      "./masked_dataset_face_cropped/32/f_32_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 34.235610856436004 %\n",
      "\n",
      "./masked_dataset_face_cropped/32/f_32_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 26.76076118250123 %\n",
      "\n",
      "./masked_dataset_face_cropped/32/h_32_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 33.58822268276996 %\n",
      "\n",
      "./masked_dataset_face_cropped/32/h_32_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 23.18010550113037 %\n",
      "\n",
      "./masked_dataset_face_cropped/32/h_32_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 21.491352424156506 %\n",
      "\n",
      "./masked_dataset_face_cropped/34/f_34_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 41.21556036735608 %\n",
      "\n",
      "./masked_dataset_face_cropped/34/f_34_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 34.81769707450641 %\n",
      "\n",
      "./masked_dataset_face_cropped/34/f_34_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 33.50421348314607 %\n",
      "\n",
      "./masked_dataset_face_cropped/34/h_34_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 34.886658712892135 %\n",
      "\n",
      "./masked_dataset_face_cropped/34/h_34_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 36.58299716121321 %\n",
      "\n",
      "./masked_dataset_face_cropped/34/h_34_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 26.679091104580316 %\n",
      "\n",
      "./masked_dataset_face_cropped/36/f_36_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 18.39780236097706 %\n",
      "\n",
      "./masked_dataset_face_cropped/36/f_36_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 15.396451846488052 %\n",
      "\n",
      "./masked_dataset_face_cropped/36/f_36_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 10.294925810588019 %\n",
      "\n",
      "./masked_dataset_face_cropped/36/h_36_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 9.87546044553587 %\n",
      "\n",
      "./masked_dataset_face_cropped/36/h_36_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 8.645916467145517 %\n",
      "\n",
      "./masked_dataset_face_cropped/36/h_36_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 14.62166053431451 %\n",
      "\n",
      "./masked_dataset_face_cropped/38/f_38_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 10.659095140569725 %\n",
      "\n",
      "./masked_dataset_face_cropped/38/f_38_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 12.494048185887058 %\n",
      "\n",
      "./masked_dataset_face_cropped/38/f_38_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 11.471568892493467 %\n",
      "\n",
      "./masked_dataset_face_cropped/38/h_38_bott_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 8.118705997682916 %\n",
      "\n",
      "./masked_dataset_face_cropped/38/h_38_fron_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 0.08416496332812312 %\n",
      "\n",
      "./masked_dataset_face_cropped/38/h_38_topp_face.jpg\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "the ratio of mask: 9.837606837606838 %\n",
      "\n",
      "전체 비율:  22.979392175164374 %\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 마스크 검출이 잘 되는 사람 폴더\n",
    "folder_list = ['03', '04', '05', '06', '08', '09', '10', '14', '15', '17', '20', '21', '24', '25', '28', '31', '32', '34', '36', '38']\n",
    "\n",
    "sum_ratio = 0\n",
    "# 마스크 비율을 계산할 이미지들\n",
    "for i in folder_list:\n",
    "    path_dir = \"./masked_dataset_face_cropped/\" + i\n",
    "    file_list = os.listdir(path_dir)\n",
    "\n",
    "    for j in range(len(file_list)):\n",
    "        filename = file_list[j]\n",
    "        file_path = path_dir + \"/\" + filename\n",
    "        \n",
    "        gmm_components=5\n",
    "        num_iters=1\n",
    "        gamma=50\n",
    "        flag=8\n",
    "    #     img = cv2.imread(filename)\n",
    "        img = cv2.imread(file_path)\n",
    "        print(file_path)\n",
    "\n",
    "        # auto_grabcut\n",
    "        img2 = img.copy() # a copy of original image\n",
    "        mask = np.zeros(img.shape[:2], dtype=np.uint8)  # mask initialized to BG\n",
    "        auto_grabcut = np.zeros(img.shape, np.uint8)    # output image to be shown\n",
    "    #     print(img.shape)\n",
    "\n",
    "        rect = (1, 1, img.shape[1]-2, img.shape[0]-2)\n",
    "        rectangle = True # test\n",
    "        rect_over =  True # test\n",
    "        print(rect, rect)\n",
    "        gc = GrabCut(img2, mask,num_iters,gamma,gmm_components, flag,rect)\n",
    "\n",
    "        mask2 = np.where((mask == 1) + (mask == 3), 255, 0).astype('uint8')\n",
    "        auto_grabcut = cv2.bitwise_and(img2, img2, mask=mask2)\n",
    "\n",
    "        # hsv_mask\n",
    "        hsv = cv2.cvtColor(auto_grabcut, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(hsv)\n",
    "        s = cv2.inRange(s, 0, 50) ##### hsv 범위 조절\n",
    "        hsv_mask = cv2.bitwise_and(hsv, hsv, mask = s)\n",
    "        hsv_mask = cv2.cvtColor(hsv_mask, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "        # calculate ratio\n",
    "        img_gray = cv2.cvtColor(hsv_mask, cv2.COLOR_BGR2GRAY)\n",
    "        img_bin = np.zeros(img_gray.shape)\n",
    "\n",
    "        no_mask_px_cnt = 0\n",
    "        mask_px_cnt = 0\n",
    "\n",
    "        for i in range(0, img_gray.shape[0]):\n",
    "            for j in range(0, img_gray.shape[1]):\n",
    "                if img_gray[i][j] == 0:\n",
    "                    img_bin[i][j] = 0 # no_mask_px\n",
    "                    no_mask_px_cnt = no_mask_px_cnt + 1\n",
    "                else:\n",
    "                    img_bin[i][j] = 255 # mask_px\n",
    "                    mask_px_cnt = mask_px_cnt + 1\n",
    "                    ratio = mask_px_cnt/(mask_px_cnt+no_mask_px_cnt)\n",
    "        sum_ratio = sum_ratio + ratio\n",
    "\n",
    "        print(\"the ratio of mask:\", ratio*100, \"%\")\n",
    "        print(\"\")\n",
    "\n",
    "avg_ratio = sum_ratio / (len(folder_list) * len(file_list))        \n",
    "print(\"전체 비율: \", avg_ratio*100, '%')\n",
    "# 마스크로 가려진 부분의 비율(단위: %)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "# cv2.namedWindow(\"1. input\", cv2.WINDOW_NORMAL) # 창 크기 조절 가능\n",
    "# cv2.imshow(\"1. input\", img)\n",
    "\n",
    "# cv2.namedWindow(\"2. auto_grabcut\", cv2.WINDOW_NORMAL) # 창 크기 조절 가능\n",
    "# cv2.imshow(\"2. auto_grabcut\", auto_grabcut)\n",
    "\n",
    "# cv2.namedWindow(\"3. hsv\", cv2.WINDOW_NORMAL) # 창 크기 조절 가능\n",
    "# cv2.imshow(\"3. hsv\", hsv_mask)\n",
    "\n",
    "# cv2.namedWindow(\"4. binary image\", cv2.WINDOW_NORMAL) # 창 크기 조절 가능\n",
    "# cv2.imshow(\"4. binary image\",img_bin)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여기까지 실행 (Cell - Run All Above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1단계. 배경영역 제거하기 auto_grabcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 120, 3)\n",
      "(1, 1, 118, 118) (1, 1, 118, 118)\n",
      "(pr_)bgd count: 476, (pr_)fgd count: 13924\n",
      "Beta: 0.0004286698417465072\n",
      "bgd count: 476, fgd count: 0, uncertain count: 13924\n",
      "foreground pixels: 9241, background pixels: 5161\n",
      "(pr_)bgd count: 5160, (pr_)fgd count: 9240\n"
     ]
    }
   ],
   "source": [
    "filename=\"./masked_dataset_face_cropped/35/f_35_fron_face.jpg\"\n",
    "gmm_components=5\n",
    "num_iters=1\n",
    "gamma=50\n",
    "flag=8\n",
    "img = cv2.imread(filename)\n",
    "\n",
    "img2 = img.copy() # a copy of original image\n",
    "\n",
    "mask = np.zeros(img.shape[:2], dtype=np.uint8)  # mask initialized to BG\n",
    "auto_grabcut = np.zeros(img.shape, np.uint8)           # output image to be shown\n",
    "\n",
    "# # input and output windows\n",
    "# cv2.namedWindow('output')\n",
    "# cv2.namedWindow('input')\n",
    "# # cv2.setMouseCallback('input', onmouse)\n",
    "# cv2.moveWindow('input', img.shape[1]+10, 90)\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "# print(\" Instructions: \\n\")\n",
    "# print(\" Draw a rectangle around the object using right mouse button \\n\")\n",
    "\n",
    "rect = (1, 1, img.shape[1]-2, img.shape[0]-2)\n",
    "rectangle = True # test\n",
    "rect_over =  True # test\n",
    "print(rect, rect)\n",
    "gc = GrabCut(img2, mask,num_iters,gamma,gmm_components, flag,rect)\n",
    "\n",
    "mask2 = np.where((mask == 1) + (mask == 3), 255, 0).astype('uint8')\n",
    "auto_grabcut = cv2.bitwise_and(img2, img2, mask=mask2)\n",
    "\n",
    "# 결과 출력\n",
    "# cv2.namedWindow(\"input\", cv2.WINDOW_NORMAL) # 창 크기 조절 가능\n",
    "# cv2.imshow(\"input\", img)\n",
    "\n",
    "# cv2.namedWindow(\"auto_grabcut\", cv2.WINDOW_NORMAL) # 창 크기 조절 가능\n",
    "# cv2.imshow(\"auto_grabcut\", auto_grabcut)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2단계. 마스크 영역만 검출하기(HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "hsv = cv2.cvtColor(auto_grabcut, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "h, s, v = cv2.split(hsv)\n",
    "print(s)\n",
    "\n",
    "s = cv2.inRange(s, 0, 30)\n",
    "hsv_mask = cv2.bitwise_and(hsv, hsv, mask = s)\n",
    "hsv_mask = cv2.cvtColor(hsv_mask, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "# 결과 출력\n",
    "cv2.namedWindow(\"auto_grabcut\", cv2.WINDOW_NORMAL) # 창 크기 조절 가능\n",
    "cv2.imshow(\"auto_grabcut\", auto_grabcut)\n",
    "\n",
    "cv2.namedWindow(\"hsv\", cv2.WINDOW_NORMAL) # 창 크기 조절 가능\n",
    "cv2.imshow(\"hsv\", hsv_mask)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3단계. 마스크 영역 비율 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the ratio of mask: 29.75 %\n"
     ]
    }
   ],
   "source": [
    "img_gray = cv2.cvtColor(hsv_mask, cv2.COLOR_BGR2GRAY)\n",
    "img_bin = np.zeros(img_gray.shape)\n",
    "\n",
    "no_mask_px_cnt = 0\n",
    "mask_px_cnt = 0\n",
    "\n",
    "for i in range(0, img_gray.shape[0]):\n",
    "    for j in range(0, img_gray.shape[1]):\n",
    "        if img_gray[i][j] == 0:\n",
    "            img_bin[i][j] = 0 # no_mask_px\n",
    "            no_mask_px_cnt = no_mask_px_cnt + 1\n",
    "        else:\n",
    "            img_bin[i][j] = 255 # mask_px\n",
    "            mask_px_cnt = mask_px_cnt + 1\n",
    "\n",
    "print(\"the ratio of mask:\", mask_px_cnt/(mask_px_cnt+no_mask_px_cnt)*100, \"%\")\n",
    "# 마스크로 가려진 부분의 비율(단위: %)\n",
    "\n",
    "# 결과 출력\n",
    "cv2.namedWindow(\"gray image\", cv2.WINDOW_NORMAL) # 창 크기 조절 가능\n",
    "cv2.imshow(\"gray image\",img_gray)\n",
    "\n",
    "cv2.namedWindow(\"binary image\", cv2.WINDOW_NORMAL) # 창 크기 조절 가능\n",
    "cv2.imshow(\"binary image\",img_bin)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 피부 영역 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# #Open a simple image\n",
    "# img=cv2.imread(\"f_19_bott_periocular.jpg\")\n",
    "\n",
    "# #converting from gbr to hsv color space\n",
    "# img_HSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "# #skin color range for hsv color space \n",
    "# HSV_mask = cv2.inRange(img_HSV, (0, 15, 0), (17,170,255)) \n",
    "# HSV_mask = cv2.morphologyEx(HSV_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "# #converting from gbr to YCbCr color space\n",
    "# img_YCrCb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "# #skin color range for hsv color space \n",
    "# YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255,180,135)) \n",
    "# YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "# #merge skin detection (YCbCr and hsv)\n",
    "# global_mask=cv2.bitwise_and(YCrCb_mask,HSV_mask)\n",
    "# global_mask=cv2.medianBlur(global_mask,3)\n",
    "# global_mask = cv2.morphologyEx(global_mask, cv2.MORPH_OPEN, np.ones((4,4), np.uint8))\n",
    "\n",
    "\n",
    "# HSV_result = cv2.bitwise_not(HSV_mask)\n",
    "# YCrCb_result = cv2.bitwise_not(YCrCb_mask)\n",
    "# global_result=cv2.bitwise_not(global_mask)\n",
    "\n",
    "\n",
    "# #show results\n",
    "# cv2.imshow(\"1_HSV.jpg\",HSV_result)\n",
    "# cv2.imshow(\"2_YCbCr.jpg\",YCrCb_result)\n",
    "# cv2.imshow(\"3_global_result.jpg\",global_result)\n",
    "# cv2.imshow(\"Image.jpg\",img)\n",
    "# # cv2.imwrite(\"1_HSV.jpg\",HSV_result)\n",
    "# # cv2.imwrite(\"2_YCbCr.jpg\",YCrCb_result)\n",
    "# # cv2.imwrite(\"3_global_result.jpg\",global_result)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ny_tf",
   "language": "python",
   "name": "ny_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
